{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  torch\n",
    "from    torch import optim, nn\n",
    "import  visdom\n",
    "import  torchvision\n",
    "from    torch.utils.data import DataLoader\n",
    "\n",
    "from    resnet18 import ResNet18\n",
    "#from    densenet import DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from    stone import Stone\n",
    "from    stone1 import Stone1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsz = 7\n",
    "lr = 1e-3\n",
    "epochs = 30\n",
    "\n",
    "device = torch.device('cuda')\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "\n",
    "train_db = Stone('stone', 224, mode='train')\n",
    "val_db = Stone('stone', 224, mode='val')\n",
    "train_loader = DataLoader(train_db, batch_size=batchsz, shuffle=True)\n",
    "val_loader = DataLoader(val_db, batch_size=batchsz)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "test_db = Stone1('stone', 224, mode='test')\n",
    "test_loader = DataLoader(test_db, batch_size=batchsz,shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "viz = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalute(model, loader):\n",
    "    model.eval() #实际估计时使用\n",
    "    \n",
    "    correct = 0\n",
    "    cc=0\n",
    "    total = len(loader.dataset)\n",
    "\n",
    "    for x,y in loader:\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(x)\n",
    "            pred = logits.argmax(dim=1)\n",
    "        correct += torch.eq(pred, y).sum().float().item()\n",
    "\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    model = ResNet18(7).to(device)\n",
    "    #model = DenseNet(growth_rate=32, block_config=(6, 12, 24, 16), num_init_features=64,\n",
    "    #             bn_size=4, compression_rate=0.5, drop_rate=0, num_classes=7).to(device)\n",
    "    \n",
    "    #model.load_state_dict(torch.load('best.mdl'))\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criteon = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    best_acc, best_epoch = 0, 0\n",
    "    global_step = 0\n",
    "    #viz.line([0], [-1], win='loss', opts=dict(title='loss'))\n",
    "    #viz.line([0], [-1], win='val_acc', opts=dict(title='val_acc'))\n",
    "    viz.line([0], [0], win='损失loss', opts=dict(title='损失loss'))\n",
    "    viz.line([0], [0], win='交叉验证集测试结果', opts=dict(title='交叉验证集测试结果'))\n",
    "    viz.line([0], [0], win='交叉验证集的测试结果', opts=dict(title='交叉验证集的测试结果'))\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for step, (x,y) in enumerate(train_loader):\n",
    "\n",
    "            # x: [b, 3, 224, 224], y: [b]\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            model.train()\n",
    "            logits = model(x)\n",
    "            loss = criteon(logits, y)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #viz.line([loss.item()], [global_step], win='loss', update='append')\n",
    "            viz.line([loss.item()], [global_step], win='损失loss', update='append')\n",
    "            global_step += 1\n",
    "            print('global_step:', global_step,'loss.item:',loss.item())\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "\n",
    "            val_acc = evalute(model, val_loader)\n",
    "            \n",
    "            print('val_acc:', val_acc, 'epoch:', epoch)\n",
    "\n",
    "\n",
    "            if val_acc > best_acc:\n",
    "                best_epoch = epoch\n",
    "                best_acc = val_acc\n",
    "\n",
    "                torch.save(model.state_dict(), 'best.mdl')\n",
    "                viz.line([val_acc], [epoch+1], win='交叉验证集测试结果', update='append')\n",
    "                \n",
    "            #viz.line([val_acc], [global_step], win='val_acc', update='append')\n",
    "            viz.line([val_acc], [epoch+1], win='交叉验证集的测试结果', update='append')\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "    print('best acc:', best_acc, 'best epoch:', best_epoch)\n",
    "\n",
    "    model.load_state_dict(torch.load('best.mdl'))\n",
    "    print('loaded from ckpt!')\n",
    "\n",
    "    test_acc = evalute(model, test_loader)\n",
    "    print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step: 1 loss.item: 2.3074634075164795\n",
      "global_step: 2 loss.item: 17.286062240600586\n",
      "global_step: 3 loss.item: 2.745180368423462\n",
      "global_step: 4 loss.item: 1.0308853387832642\n",
      "global_step: 5 loss.item: 3.2761521339416504\n",
      "global_step: 6 loss.item: 9.268641471862793\n",
      "global_step: 7 loss.item: 7.042732238769531\n",
      "global_step: 8 loss.item: 3.8830296993255615\n",
      "val_acc: 0.14285714285714285 epoch: 0\n",
      "global_step: 9 loss.item: 14.473143577575684\n",
      "global_step: 10 loss.item: 16.312253952026367\n",
      "global_step: 11 loss.item: 10.252202987670898\n",
      "global_step: 12 loss.item: 8.386587142944336\n",
      "global_step: 13 loss.item: 2.464073657989502\n",
      "global_step: 14 loss.item: 15.272127151489258\n",
      "global_step: 15 loss.item: 8.305219650268555\n",
      "global_step: 16 loss.item: 1.8907034397125244\n",
      "val_acc: 0.2857142857142857 epoch: 1\n",
      "global_step: 17 loss.item: 2.42449688911438\n",
      "global_step: 18 loss.item: 1.7587850093841553\n",
      "global_step: 19 loss.item: 1.4625808000564575\n",
      "global_step: 20 loss.item: 24.406875610351562\n",
      "global_step: 21 loss.item: 4.819911479949951\n",
      "global_step: 22 loss.item: 6.980627536773682\n",
      "global_step: 23 loss.item: 8.76497745513916\n",
      "global_step: 24 loss.item: 11.65627384185791\n",
      "val_acc: 0.42857142857142855 epoch: 2\n",
      "global_step: 25 loss.item: 1.4733370542526245\n",
      "global_step: 26 loss.item: 1.2109220027923584\n",
      "global_step: 27 loss.item: 7.269067287445068\n",
      "global_step: 28 loss.item: 1.4022866487503052\n",
      "global_step: 29 loss.item: 1.4349368810653687\n",
      "global_step: 30 loss.item: 1.9639790058135986\n",
      "global_step: 31 loss.item: 1.8964601755142212\n",
      "global_step: 32 loss.item: 1.747771143913269\n",
      "val_acc: 0.14285714285714285 epoch: 3\n",
      "global_step: 33 loss.item: 1.4787206649780273\n",
      "global_step: 34 loss.item: 15.138063430786133\n",
      "global_step: 35 loss.item: 1.757765531539917\n",
      "global_step: 36 loss.item: 6.019742488861084\n",
      "global_step: 37 loss.item: 3.8393054008483887\n",
      "global_step: 38 loss.item: 7.314924716949463\n",
      "global_step: 39 loss.item: 1.2998216152191162\n",
      "global_step: 40 loss.item: 3.1127829551696777\n",
      "val_acc: 0.42857142857142855 epoch: 4\n",
      "global_step: 41 loss.item: 0.8362166285514832\n",
      "global_step: 42 loss.item: 0.839320957660675\n",
      "global_step: 43 loss.item: 1.1385210752487183\n",
      "global_step: 44 loss.item: 1.5906745195388794\n",
      "global_step: 45 loss.item: 4.27372407913208\n",
      "global_step: 46 loss.item: 1.9828425645828247\n",
      "global_step: 47 loss.item: 5.9107537269592285\n",
      "global_step: 48 loss.item: 6.843842506408691\n",
      "val_acc: 0.5714285714285714 epoch: 5\n",
      "global_step: 49 loss.item: 8.387733459472656\n",
      "global_step: 50 loss.item: 1.5234479904174805\n",
      "global_step: 51 loss.item: 1.4256142377853394\n",
      "global_step: 52 loss.item: 1.596906304359436\n",
      "global_step: 53 loss.item: 1.490641474723816\n",
      "global_step: 54 loss.item: 1.5240904092788696\n",
      "global_step: 55 loss.item: 10.681509017944336\n",
      "global_step: 56 loss.item: 3.9480435848236084\n",
      "val_acc: 0.0 epoch: 6\n",
      "global_step: 57 loss.item: 1.568233847618103\n",
      "global_step: 58 loss.item: 1.7363253831863403\n",
      "global_step: 59 loss.item: 1.1168467998504639\n",
      "global_step: 60 loss.item: 1.3555192947387695\n",
      "global_step: 61 loss.item: 1.442728877067566\n",
      "global_step: 62 loss.item: 1.4609838724136353\n",
      "global_step: 63 loss.item: 1.5507806539535522\n",
      "global_step: 64 loss.item: 3.1929569244384766\n",
      "val_acc: 0.14285714285714285 epoch: 7\n",
      "global_step: 65 loss.item: 1.0319195985794067\n",
      "global_step: 66 loss.item: 1.432237982749939\n",
      "global_step: 67 loss.item: 1.1209474802017212\n",
      "global_step: 68 loss.item: 2.7335777282714844\n",
      "global_step: 69 loss.item: 1.098388433456421\n",
      "global_step: 70 loss.item: 1.966552495956421\n",
      "global_step: 71 loss.item: 2.756862163543701\n",
      "global_step: 72 loss.item: 1.545724630355835\n",
      "val_acc: 0.14285714285714285 epoch: 8\n",
      "global_step: 73 loss.item: 1.1849462985992432\n",
      "global_step: 74 loss.item: 1.525236964225769\n",
      "global_step: 75 loss.item: 0.9688401818275452\n",
      "global_step: 76 loss.item: 3.9493255615234375\n",
      "global_step: 77 loss.item: 0.7557694315910339\n",
      "global_step: 78 loss.item: 1.4992506504058838\n",
      "global_step: 79 loss.item: 1.6886268854141235\n",
      "global_step: 80 loss.item: 2.98351788520813\n",
      "val_acc: 0.14285714285714285 epoch: 9\n",
      "global_step: 81 loss.item: 0.8834816813468933\n",
      "global_step: 82 loss.item: 1.5827239751815796\n",
      "global_step: 83 loss.item: 0.9637665748596191\n",
      "global_step: 84 loss.item: 0.7124108672142029\n",
      "global_step: 85 loss.item: 1.0772186517715454\n",
      "global_step: 86 loss.item: 1.4218486547470093\n",
      "global_step: 87 loss.item: 0.9247407913208008\n",
      "global_step: 88 loss.item: 1.1571900844573975\n",
      "val_acc: 0.2857142857142857 epoch: 10\n",
      "global_step: 89 loss.item: 1.3953306674957275\n",
      "global_step: 90 loss.item: 0.70390784740448\n",
      "global_step: 91 loss.item: 1.1439549922943115\n",
      "global_step: 92 loss.item: 1.0125653743743896\n",
      "global_step: 93 loss.item: 4.628296852111816\n",
      "global_step: 94 loss.item: 1.1409178972244263\n",
      "global_step: 95 loss.item: 0.9070109128952026\n",
      "global_step: 96 loss.item: 0.6723150610923767\n",
      "val_acc: 0.2857142857142857 epoch: 11\n",
      "global_step: 97 loss.item: 0.9885925650596619\n",
      "global_step: 98 loss.item: 0.8818969130516052\n",
      "global_step: 99 loss.item: 1.417281985282898\n",
      "global_step: 100 loss.item: 2.3725333213806152\n",
      "global_step: 101 loss.item: 1.5610542297363281\n",
      "global_step: 102 loss.item: 1.3675076961517334\n",
      "global_step: 103 loss.item: 0.3443847596645355\n",
      "global_step: 104 loss.item: 3.9192769527435303\n",
      "val_acc: 0.14285714285714285 epoch: 12\n",
      "global_step: 105 loss.item: 0.8366981148719788\n",
      "global_step: 106 loss.item: 0.6133664846420288\n",
      "global_step: 107 loss.item: 0.6638535261154175\n",
      "global_step: 108 loss.item: 0.9642065763473511\n",
      "global_step: 109 loss.item: 0.7107356190681458\n",
      "global_step: 110 loss.item: 10.186671257019043\n",
      "global_step: 111 loss.item: 0.5704990029335022\n",
      "global_step: 112 loss.item: 1.5864375829696655\n",
      "val_acc: 0.42857142857142855 epoch: 13\n",
      "global_step: 113 loss.item: 1.6922162771224976\n",
      "global_step: 114 loss.item: 0.6215575933456421\n",
      "global_step: 115 loss.item: 1.2469536066055298\n",
      "global_step: 116 loss.item: 1.0782759189605713\n",
      "global_step: 117 loss.item: 3.3463213443756104\n",
      "global_step: 118 loss.item: 0.7780095338821411\n",
      "global_step: 119 loss.item: 1.6303178071975708\n",
      "global_step: 120 loss.item: 1.2260115146636963\n",
      "val_acc: 0.2857142857142857 epoch: 14\n",
      "global_step: 121 loss.item: 3.360696792602539\n",
      "global_step: 122 loss.item: 1.1458064317703247\n",
      "global_step: 123 loss.item: 1.1302534341812134\n",
      "global_step: 124 loss.item: 0.7750849723815918\n",
      "global_step: 125 loss.item: 0.27263399958610535\n",
      "global_step: 126 loss.item: 0.5257270336151123\n",
      "global_step: 127 loss.item: 0.6508709788322449\n",
      "global_step: 128 loss.item: 0.7331176400184631\n",
      "val_acc: 0.42857142857142855 epoch: 15\n",
      "global_step: 129 loss.item: 0.5501737594604492\n",
      "global_step: 130 loss.item: 1.061979055404663\n",
      "global_step: 131 loss.item: 0.8930726051330566\n",
      "global_step: 132 loss.item: 0.69383704662323\n",
      "global_step: 133 loss.item: 0.7276100516319275\n",
      "global_step: 134 loss.item: 0.7091802358627319\n",
      "global_step: 135 loss.item: 0.4034448564052582\n",
      "global_step: 136 loss.item: 0.6588115692138672\n",
      "val_acc: 0.42857142857142855 epoch: 16\n",
      "global_step: 137 loss.item: 0.3677919805049896\n",
      "global_step: 138 loss.item: 0.5842849016189575\n",
      "global_step: 139 loss.item: 0.5597302913665771\n",
      "global_step: 140 loss.item: 1.4282386302947998\n",
      "global_step: 141 loss.item: 0.2084777057170868\n",
      "global_step: 142 loss.item: 0.9358958005905151\n",
      "global_step: 143 loss.item: 0.43205538392066956\n",
      "global_step: 144 loss.item: 1.1096793413162231\n",
      "val_acc: 0.2857142857142857 epoch: 17\n",
      "global_step: 145 loss.item: 0.43912601470947266\n",
      "global_step: 146 loss.item: 0.5567363500595093\n",
      "global_step: 147 loss.item: 0.3059411942958832\n",
      "global_step: 148 loss.item: 0.9882153272628784\n",
      "global_step: 149 loss.item: 0.3711049258708954\n",
      "global_step: 150 loss.item: 0.915659487247467\n",
      "global_step: 151 loss.item: 0.7792831659317017\n",
      "global_step: 152 loss.item: 0.378081738948822\n",
      "val_acc: 0.2857142857142857 epoch: 18\n",
      "global_step: 153 loss.item: 0.6721881031990051\n",
      "global_step: 154 loss.item: 0.34868672490119934\n",
      "global_step: 155 loss.item: 0.34306082129478455\n",
      "global_step: 156 loss.item: 0.8445056676864624\n",
      "global_step: 157 loss.item: 0.3498130738735199\n",
      "global_step: 158 loss.item: 0.580662727355957\n",
      "global_step: 159 loss.item: 0.21469619870185852\n",
      "global_step: 160 loss.item: 0.11258658021688461\n",
      "val_acc: 0.42857142857142855 epoch: 19\n",
      "global_step: 161 loss.item: 0.2747117877006531\n",
      "global_step: 162 loss.item: 0.40845513343811035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step: 163 loss.item: 0.06507108360528946\n",
      "global_step: 164 loss.item: 0.3193051517009735\n",
      "global_step: 165 loss.item: 0.36764636635780334\n",
      "global_step: 166 loss.item: 1.9448939561843872\n",
      "global_step: 167 loss.item: 0.41164737939834595\n",
      "global_step: 168 loss.item: 0.23092077672481537\n",
      "val_acc: 0.2857142857142857 epoch: 20\n",
      "global_step: 169 loss.item: 0.16702429950237274\n",
      "global_step: 170 loss.item: 0.6847673654556274\n",
      "global_step: 171 loss.item: 1.9854145050048828\n",
      "global_step: 172 loss.item: 0.12144631892442703\n",
      "global_step: 173 loss.item: 0.10228509455919266\n",
      "global_step: 174 loss.item: 0.06797502934932709\n",
      "global_step: 175 loss.item: 0.47763094305992126\n",
      "global_step: 176 loss.item: 0.6124639511108398\n",
      "val_acc: 0.14285714285714285 epoch: 21\n",
      "global_step: 177 loss.item: 1.981806993484497\n",
      "global_step: 178 loss.item: 0.8466750979423523\n",
      "global_step: 179 loss.item: 0.2549563944339752\n",
      "global_step: 180 loss.item: 0.14082762598991394\n",
      "global_step: 181 loss.item: 5.9217329025268555\n",
      "global_step: 182 loss.item: 0.16833452880382538\n",
      "global_step: 183 loss.item: 0.9869747161865234\n",
      "global_step: 184 loss.item: 0.3676397502422333\n",
      "val_acc: 0.5714285714285714 epoch: 22\n",
      "global_step: 185 loss.item: 0.7096367478370667\n",
      "global_step: 186 loss.item: 1.1903489828109741\n",
      "global_step: 187 loss.item: 0.6028119325637817\n",
      "global_step: 188 loss.item: 0.10448801517486572\n",
      "global_step: 189 loss.item: 0.16609354317188263\n",
      "global_step: 190 loss.item: 1.1180628538131714\n",
      "global_step: 191 loss.item: 0.3376352787017822\n",
      "global_step: 192 loss.item: 0.16984431445598602\n",
      "val_acc: 0.2857142857142857 epoch: 23\n",
      "global_step: 193 loss.item: 0.2926737666130066\n",
      "global_step: 194 loss.item: 1.0598176717758179\n",
      "global_step: 195 loss.item: 0.05044075474143028\n",
      "global_step: 196 loss.item: 0.26407527923583984\n",
      "global_step: 197 loss.item: 1.4806348085403442\n",
      "global_step: 198 loss.item: 0.07479523122310638\n",
      "global_step: 199 loss.item: 0.3860141932964325\n",
      "global_step: 200 loss.item: 0.621586263179779\n",
      "val_acc: 0.5714285714285714 epoch: 24\n",
      "global_step: 201 loss.item: 0.10478059947490692\n",
      "global_step: 202 loss.item: 0.39769870042800903\n",
      "global_step: 203 loss.item: 0.20689712464809418\n",
      "global_step: 204 loss.item: 1.4874192476272583\n",
      "global_step: 205 loss.item: 0.23411165177822113\n",
      "global_step: 206 loss.item: 2.4414443969726562\n",
      "global_step: 207 loss.item: 0.10650430619716644\n",
      "global_step: 208 loss.item: 0.1401589810848236\n",
      "val_acc: 0.42857142857142855 epoch: 25\n",
      "global_step: 209 loss.item: 0.36302146315574646\n",
      "global_step: 210 loss.item: 0.9206627011299133\n",
      "global_step: 211 loss.item: 0.09447168558835983\n",
      "global_step: 212 loss.item: 0.060459841042757034\n",
      "global_step: 213 loss.item: 0.06865895539522171\n",
      "global_step: 214 loss.item: 0.3866310715675354\n",
      "global_step: 215 loss.item: 0.9527620673179626\n",
      "global_step: 216 loss.item: 0.14315557479858398\n",
      "val_acc: 0.2857142857142857 epoch: 26\n",
      "global_step: 217 loss.item: 0.18542063236236572\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(7).to(device)\n",
    "model.load_state_dict(torch.load('best.mdl'))\n",
    "print('loaded from ckpt!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = evalute(model, test_loader)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
